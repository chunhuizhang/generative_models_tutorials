{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce7344a-d185-4dbe-8cd6-4661641da5aa",
   "metadata": {},
   "source": [
    "- Modeling in high-dimensional spaces is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf285b32-1554-43c4-8c7c-979d487cc935",
   "metadata": {},
   "source": [
    "## Latent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc1949-2b2f-480b-a895-f92e2efe4e57",
   "metadata": {},
   "source": [
    "\n",
    "Generative Process\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\mathbf z\\sim p_\\lambda(\\mathbf z)\\\\\n",
    "&x\\sim p_\\theta(x|z)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Log of Marginal distribution:\n",
    "\n",
    "$$\n",
    "\\log p_\\theta(\\mathbf x)=\\log \\int p_\\theta(\\mathbf x|z)p_\\lambda(\\mathbf z)d\\mathbf z\n",
    "$$\n",
    "\n",
    "Variational Inference for LVM（Latent Variable Models）\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log p_{\\theta}(x) &= \\log \\int p_{\\theta}(x|z) \\, p_{\\lambda}(z) \\, dz \\\\\n",
    "&= \\log \\int \\frac{q_{\\phi}(z|x)}{q_{\\phi}(z|x)} \\, p_{\\theta}(x|z) \\, p_{\\lambda}(z) \\, dz \\\\\n",
    "&\\geq \\int q_{\\phi}(z|x) \\log \\frac{p_{\\theta}(x|z) \\, p_{\\lambda}(z)}{q_{\\phi}(z|x)} \\, dz \\\\\n",
    "&= \\mathbb{E}_{z \\sim q_{\\phi}(z|x)} \\left[ \\log p_{\\theta}(x|z) \\right] - \\text{KL} \\left( q_{\\phi}(z|x) \\| p_{\\lambda}(z) \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- $q_\\phi(z|x)$: Variational posterior\n",
    "    - encoder：变分后验\n",
    "    - decoder：likelihood function\n",
    "- $p_\\lambda(z)$: marginal\n",
    "- 最后一行的第一项（$\\mathbb E_{z \\sim q_\\phi(z|x)}\\left[ \\log p_{\\theta}(x|z) \\right]$）衡量的是重构误差（reconstruction error）\n",
    "    - 它可以被解释为在潜在变量 $z$ 从近似后验分布 $q_\\phi(z|x)$ 中采样时，数据 $x$ 的重构对数似然的期望。\n",
    "    - 衡量的是模型从潜在空间生成数据与原始数据的匹配程度。\n",
    "    - 对数似然越大，说明生成的数据 $x$ 越接近原始数据 $x$，重构误差越小。\n",
    "- 第二项，则相当于 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6dd01-2bb3-486b-b1e1-63dc944aded6",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee50a80-6c3d-4e65-86ee-8f97745447a9",
   "metadata": {},
   "source": [
    "$$\n",
    "x \\rightarrow z\n",
    "$$\n",
    "\n",
    "\n",
    "- encoder 编码器将输入数据 $x$ 映射到潜在变量 $z$。\n",
    "    - latent space 上的低维特性，通过编码器，模型学习如何将高维的数据 $x$ 压缩到一个低维的潜在表示 $z$ 中。\n",
    "- inference 推断（不同于推理）过程\n",
    "    - Variational Inference：变分推断，这个过程通常是通过一个高斯分布来表示，即 $q(z|x)$ 是一个参数化的分布（$q_\\theta(z|x)$），它估计给定 $x$ 的潜在变量 $z$ 的后验分布。\n",
    "\n",
    "- 但这一步，即使用一个 Neutral Network 去表征，仍然是十分困难的（主要是分母部分）\n",
    "\n",
    "$$\n",
    "q(z|x)=\\frac{p(z)p(x|z)}{p(x)}=\\frac{p(z)p(x|z)}{\\int p(x,z) dz}\n",
    "$$\n",
    "\n",
    "对于\n",
    "\n",
    "$$\n",
    "z\\rightarrow x\n",
    "$$\n",
    "\n",
    "- decoder：解码器，重构；\n",
    "- generative model（生成模型）个过程通常是通过另一个高斯分布来表示，即 $p(x|z)$ 是一个参数化的分布，它表示给定潜在变量 𝑧 的数据 x 的生成分布。\n",
    "\n",
    "\n",
    "对于 diffusion model\n",
    "\n",
    "$$\n",
    "x_0\\rightarrow\\underbrace{x_1\\rightarrow x_2\\cdots \\rightarrow x_T}_{z}\n",
    "$$\n",
    "\n",
    "- 逐级加噪的过程相当于从 $x$ 映射到 $z$，站在概率图的视角"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898495cd-7da7-4ae5-bb77-0d89a42f7984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
